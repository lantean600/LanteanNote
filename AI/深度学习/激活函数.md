---
layout: default
title: "激活函数"
mathjax: true
---

激活函数主要用于引入非线性，使得模型可以学习复杂数据。
## sigmoid
将任意实数映射到0~1之间，输出可解释为概率

```py
def sigmoid(x):
    return 1 / (1 + np.exp(-x))
    
def sigmoid_grad(x):
    return (1.0 - sigmoid(x)) * sigmoid(x)
```

## relu
负值截断为0，正值线性通过。
一定程度缓解梯度消失问题。

```py
def relu(x):
    return np.maximum(0, x)
    
def relu_grad(x):
    grad = np.zeros_like(x)
    grad[x>=0] = 1
    return grad
```

## softmax
将任意实数向量转换为概率分布（和为1）

```
def softmax(x):
    x = x - np.max(x, axis=-1, keepdims=True)
    return np.exp(x) / np.sum(np.exp(x), axis=-1, keepdims=True)
```
