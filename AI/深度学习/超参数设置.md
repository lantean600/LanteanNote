步骤：
1. 设定超参数的范围。
2. 从设定的超参数范围中随机采样。 
3. 使用步骤 2 中采样到的超参数的值进行学习，通过验证数据评估识别精 度（但是要将 epoch 设置得很小）。 
4. 重复步骤 2 和步骤 3（100 次等），根据它们的识别精度的结果，缩小超参数的范围。

反复进行上述操作，不断缩小超参数的范围，在缩小到一定程度时，从该范围中选出一个超参数的值。

```py
import numpy as np

# 1. 定义范围
optimization_trial = 50  # 尝试50组参数
results = []

for _ in range(optimization_trial):
    # 2. 随机采样
    # 学习率在 10^-6 到 10^-2 之间，正则化强度在 10^-8 到 10^-4 之间
    lr = 10 ** np.random.uniform(-6, -2)
    weight_decay = 10 ** np.random.uniform(-8, -4)

    # 3. 训练并获取验证集最高准确率
    # 假设 __train 返回 (val_acc_list, train_acc_list)
    val_acc_list, _ = __train(lr, weight_decay, epocs=50)
    best_val_acc = max(val_acc_list) # 记录该组参数下的最佳表现
    
    results.append({
        'val_acc': best_val_acc,
        'lr': lr,
        'weight_decay': weight_decay
    })

# 4. 排序，筛选出最优解
results.sort(key=lambda x: x['val_acc'], reverse=True)

print("Top 5 Results:")
for i, res in enumerate(results[:5]):
    print(f"Rank {i+1}: Acc:{res['val_acc']:.4f} | lr:{res['lr']:.6e} | wd:{res['weight_decay']:.6e}")
```